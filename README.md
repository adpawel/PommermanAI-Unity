# ğŸ§  Pommerman AI â€” Unity ML-Agents

Celem projektu byÅ‚o zaprojektowanie, implementacja oraz eksperymentalna analiza Å›rodowiska gry **Pommerman**, w ktÃ³rym autonomiczni agenci uczÄ… siÄ™ skutecznych strategii dziaÅ‚ania z wykorzystaniem metod uczenia ze wzmocnieniem (Reinforcement Learning). 

## Zakres

- zaprojektowanie Å›rodowiska gry inspirowanego klasycznÄ… mechanikÄ… Bombermana, obejmujÄ…cego generowanie planszy, obsÅ‚ugÄ™ przeszkÃ³d staÅ‚ych i zniszczalnych, mechanikÄ™ Å‚adunkÃ³w oraz system kolizji,
- implementacjÄ™ agentÃ³w uczÄ…cych siÄ™ z wykorzystaniem algorytmu Proximal Policy Optimization (PPO), w tym definiowanie przestrzeni obserwacji, przestrzeni akcji oraz funkcji nagrody,
- stworzenie Å›rodowiska wieloagentowego umoÅ¼liwiajÄ…cego rywalizacjÄ™ agentÃ³w w trybach 1v1 oraz 2v2, z uwzglÄ™dnieniem mechanizmÃ³w self-play,
- analizÄ™ wpÅ‚ywu liczby obserwacji, struktury stanu oraz funkcji nagrody na stabilnoÅ›Ä‡ i jakoÅ›Ä‡ procesu uczenia,
- implementacjÄ™ mechanizmÃ³w umoÅ¼liwiajÄ…cych â€zamraÅ¼anieâ€ wytrenowanych agentÃ³w oraz trenowanie nowych agentÃ³w w ich otoczeniu,
- eksport wytrenowanych modeli do postaci umoÅ¼liwiajÄ…cej ich wykorzystanie w gotowej aplikacji (pliki .onnx) oraz przygotowanie wersji wykonywalnej programu

---
## NajwaÅ¼niejsze elementy

W poczÄ…tkowej fazie przeprowadzono eksperymentalne porÃ³wnanie algorytmÃ³w A2C (Advantage Actor-Critic) oraz PPO (Proximal Policy Optimization). Ze wzglÄ™du na wiÄ™kszÄ… stabilnoÅ›Ä‡, lepszÄ… konwergencjÄ™ i mniejszÄ… wariancjÄ™ nagrÃ³d wybrano PPO jako gÅ‚Ã³wny algorytm treningowy.

Proces uczenia byÅ‚ stopniowo rozwijany poprzez:
- **Reward Shaping** â€“ projektowanie gÄ™stej funkcji nagrody wspierajÄ…cej eksploracjÄ™, unikanie zagroÅ¼eÅ„ i zachowania ofensywne
- **Curriculum Learning** â€“ etapowe zwiÄ™kszanie zÅ‚oÅ¼onoÅ›ci Å›rodowiska (od eksploracji po peÅ‚nÄ… rywalizacjÄ™)
- **Imitation Learning / Behavioral Cloning** â€“ wykorzystanie demonstracji eksperckich do przeÅ‚amania strategii zbyt defensywnych
- **Transfer Learning** â€“ ponowne uÅ¼ycie wytrenowanych modeli jako punktu startowego dla bardziej zÅ‚oÅ¼onych wariantÃ³w
  
Self-Play â€“ trening poprzez rywalizacjÄ™ z zamroÅ¼onymi lub wczeÅ›niejszymi wersjami agenta

---

## Demo
https://github.com/user-attachments/assets/a86497cb-acd7-498b-9b89-7570371cee7f


## Wymagania

### 1. Oprogramowanie

| Komponent | Wersja (zalecana) | Uwagi |
|------------|------------------|--------|
| Unity | **2022.3 LTS** | Projekt testowany na 2022.3.x |
| Python | **3.10+** | Wymagany do ML-Agents |
| Conda / Miniconda | Dowolna aktualna wersja | Do izolacji Å›rodowiska |
| Visual Studio 2022 | Community / Professional	| Wymagane do kompilacji skryptÃ³w C# w Unity (zaznacz komponent Game development with Unity) |
| Unity Package: ML-Agents	| | Upewnij siÄ™, Å¼e jest zainstalowany w projekcie (com.unity.ml-agents) w Package Manager |

---

### 2. Instalacja Å›rodowiska Python (ML-Agents)

1. Upewnij siÄ™, Å¼e masz zainstalowanÄ… [AnacondÄ™ lub MinicondÄ™](https://docs.conda.io/en/latest/miniconda.html)
2. W katalogu projektu uruchom terminal i wpisz:

   ```bash
   conda env create -f environment.yml
   conda activate mlagents-env

    SprawdÅº, czy ML-Agents zostaÅ‚o poprawnie zainstalowane:

    mlagents-learn --help

 3. Uruchomienie projektu Unity
    
    - OtwÃ³rz Unity Hub
    - Wybierz: Add Project from Disk
    - WskaÅ¼ folder z tym projektem (tam, gdzie znajduje siÄ™ Assets/ i ProjectSettings/)
    - OtwÃ³rz scenÄ™ Scenes/SampleScene.unity

 4. Trenowanie agentÃ³w

    - Upewnij siÄ™, Å¼e Å›rodowisko Conda mlagents-env jest aktywne
    - W terminalu wpisz: `mlagents-learn pommerman_config.yaml --run-id=Pommerman_1v1_Final --force --time-scale=2.0`
    - W Unity kliknij Play â–¶ï¸
    - Trening rozpocznie siÄ™ automatycznie â€” modele zapisywane bÄ™dÄ… w folderze `results/`

    Plansza losowo generuje Å›ciany solidne i zniszczalne.

